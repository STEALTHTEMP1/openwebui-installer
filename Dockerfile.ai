FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/workspace \
    JUPYTER_ENABLE_LAB=yes \
    JUPYTER_TOKEN="" \
    JUPYTER_ALLOW_ROOT=yes

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    build-essential \
    pkg-config \
    libssl-dev \
    libffi-dev \
    libxml2-dev \
    libxslt1-dev \
    zlib1g-dev \
    libjpeg-dev \
    libpng-dev \
    libfreetype6-dev \
    liblcms2-dev \
    libwebp-dev \
    tcl8.6-dev \
    tk8.6-dev \
    python3-tk \
    vim \
    nano \
    htop \
    tree \
    jq \
    unzip \
    zip \
    rsync \
    graphviz \
    pandoc \
    texlive-xetex \
    texlive-fonts-recommended \
    texlive-plain-generic \
    && rm -rf /var/lib/apt/lists/*

# Install Node.js for additional tools
RUN curl -fsSL https://deb.nodesource.com/setup_18.x | bash - \
    && apt-get install -y nodejs \
    && rm -rf /var/lib/apt/lists/*

# Create workspace directory
WORKDIR /workspace

# Upgrade pip and install build tools
RUN pip install --upgrade pip setuptools wheel

# Install core Python dependencies
RUN pip install \
    click \
    docker \
    requests \
    rich \
    psutil

# Install Jupyter and notebook ecosystem
RUN pip install \
    jupyter==1.0.0 \
    jupyterlab==4.0.8 \
    notebook==7.0.6 \
    jupyterlab-git==0.44.0 \
    jupyter-ai==2.5.0 \
    nbconvert==7.11.0 \
    nbformat==5.9.2 \
    ipywidgets==8.1.1 \
    widgetsnbextension==4.0.9

# Install AI/ML libraries
RUN pip install \
    openai==1.3.5 \
    anthropic==0.7.7 \
    langchain==0.0.340 \
    langchain-community==0.0.3 \
    langsmith==0.0.69 \
    tiktoken==0.5.1 \
    transformers==4.35.2 \
    datasets==2.15.0 \
    accelerate==0.24.1 \
    sentencepiece==0.1.99 \
    tokenizers==0.15.0

# Install PyTorch (CPU version for lighter container)
RUN pip install torch==2.1.1+cpu torchvision==0.16.1+cpu torchaudio==2.1.1+cpu \
    --index-url https://download.pytorch.org/whl/cpu

# Install scientific computing libraries
RUN pip install \
    numpy==1.24.4 \
    pandas==2.1.3 \
    matplotlib==3.8.2 \
    seaborn==0.13.0 \
    plotly==5.17.0 \
    scikit-learn==1.3.2 \
    scipy==1.11.4 \
    statsmodels==0.14.0

# Install data processing and visualization
RUN pip install \
    altair==5.1.2 \
    bokeh==3.3.0 \
    wordcloud==1.9.2 \
    pillow==10.1.0 \
    opencv-python-headless==4.8.1.78 \
    beautifulsoup4==4.12.2 \
    lxml==4.9.3

# Install development and testing tools
RUN pip install \
    ipython==8.17.2 \
    ipdb==0.13.13 \
    pytest==7.4.3 \
    pytest-asyncio==0.21.1 \
    pytest-mock==3.12.0 \
    black==23.11.0 \
    isort==5.12.0 \
    flake8==6.1.0 \
    mypy==1.7.1

# Install API and web scraping tools
RUN pip install \
    httpx==0.25.2 \
    aiohttp==3.9.1 \
    fastapi==0.104.1 \
    uvicorn==0.24.0 \
    streamlit==1.28.2 \
    gradio==4.7.1 \
    scrapy==2.11.0 \
    selenium==4.15.2

# Install database and storage
RUN pip install \
    sqlalchemy==2.0.23 \
    alembic==1.12.1 \
    psycopg2-binary==2.9.9 \
    redis==5.0.1 \
    pymongo==4.6.0

# Install vector databases and embeddings
RUN pip install \
    chromadb==0.4.18 \
    faiss-cpu==1.7.4 \
    pinecone-client==2.2.4 \
    weaviate-client==3.25.3 \
    sentence-transformers==2.2.2

# Install notebook extensions and kernels
RUN jupyter labextension install @jupyter-widgets/jupyterlab-manager \
    && jupyter labextension install jupyterlab-plotly \
    && jupyter labextension install @bokeh/jupyter_bokeh

# Install JupyterLab AI extension
RUN pip install jupyter-ai-magics

# Create directories for AI development
RUN mkdir -p /workspace/{notebooks,models,data,prompts,experiments,logs} \
    && mkdir -p /root/.cache/huggingface \
    && mkdir -p /root/.cache/openai

# Create AI development helper scripts
RUN cat > /usr/local/bin/start-jupyter.sh << 'EOF'
#!/bin/bash
echo "ðŸ§  Starting AI Development Environment..."
echo "ðŸš€ JupyterLab will be available at: http://localhost:8889"
echo ""

# Set default environment variables if not provided
export OPENAI_API_KEY=${OPENAI_API_KEY:-""}
export ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-""}
export HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-""}

# Start JupyterLab
jupyter lab \
    --ip=0.0.0.0 \
    --port=8889 \
    --no-browser \
    --allow-root \
    --token='' \
    --notebook-dir=/workspace \
    --ServerApp.terminado_settings='{"shell_command": ["/bin/bash"]}' \
    --ServerApp.allow_origin='*' \
    --ServerApp.disable_check_xsrf=True
EOF

RUN cat > /usr/local/bin/create-notebook.sh << 'EOF'
#!/bin/bash
if [ -z "$1" ]; then
    echo "Usage: create-notebook.sh <notebook-name>"
    exit 1
fi

NOTEBOOK_NAME="$1"
NOTEBOOK_FILE="/workspace/notebooks/${NOTEBOOK_NAME}.ipynb"

cat > "$NOTEBOOK_FILE" << 'NOTEBOOK_EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Development Notebook\n",
    "\n",
    "**Created:** $(date)\n",
    "**Purpose:** [Describe the purpose of this notebook]\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# AI/ML imports\n",
    "import openai\n",
    "import anthropic\n",
    "from langchain import LLMChain\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"ðŸ§  AI Development Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY', '')\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    print(\"âœ… OpenAI API configured\")\n",
    "else:\n",
    "    print(\"âš ï¸  OpenAI API key not found\")\n",
    "\n",
    "if ANTHROPIC_API_KEY:\n",
    "    print(\"âœ… Anthropic API configured\")\n",
    "else:\n",
    "    print(\"âš ï¸  Anthropic API key not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
NOTEBOOK_EOF

echo "ðŸ““ Created notebook: $NOTEBOOK_FILE"
echo "ðŸš€ Open it in JupyterLab at: http://localhost:8889"
EOF

RUN cat > /usr/local/bin/ai-assistant.py << 'EOF'
#!/usr/bin/env python3
"""
AI Development Assistant
A CLI tool for common AI development tasks
"""

import os
import sys
import json
import argparse
from pathlib import Path

def create_prompt_template(name, description):
    """Create a new prompt template."""
    prompt_dir = Path("/workspace/prompts")
    prompt_dir.mkdir(exist_ok=True)

    prompt_file = prompt_dir / f"{name}.md"

    template = f"""# {name.replace('_', ' ').title()} Prompt

**Description:** {description}
**Created:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

## Context
Provide context about the Open WebUI Installer project and current task.

## Instructions
[Your specific instructions here]

## Expected Output
[Describe the expected format and content of the response]

## Examples
[Provide examples if applicable]

## Notes
- Keep responses focused on the Open WebUI Installer project
- Consider Docker, Python, and macOS compatibility
- Maintain code quality and testing standards
"""

    with open(prompt_file, 'w') as f:
        f.write(template)

    print(f"âœ… Created prompt template: {prompt_file}")

def list_notebooks():
    """List available notebooks."""
    notebook_dir = Path("/workspace/notebooks")
    if not notebook_dir.exists():
        print("ðŸ“‚ No notebooks directory found")
        return

    notebooks = list(notebook_dir.glob("*.ipynb"))
    if not notebooks:
        print("ðŸ““ No notebooks found")
        return

    print("ðŸ“š Available Notebooks:")
    for nb in notebooks:
        print(f"  - {nb.name}")

def main():
    parser = argparse.ArgumentParser(description='AI Development Assistant')
    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # Create prompt template
    prompt_parser = subparsers.add_parser('prompt', help='Create prompt template')
    prompt_parser.add_argument('name', help='Prompt template name')
    prompt_parser.add_argument('--description', '-d', default='AI prompt template', help='Description')

    # List notebooks
    subparsers.add_parser('notebooks', help='List available notebooks')

    args = parser.parse_args()

    if args.command == 'prompt':
        create_prompt_template(args.name, args.description)
    elif args.command == 'notebooks':
        list_notebooks()
    else:
        parser.print_help()

if __name__ == '__main__':
    main()
EOF

# Make scripts executable
RUN chmod +x /usr/local/bin/*.sh /usr/local/bin/ai-assistant.py

# Create sample notebooks and prompts
RUN mkdir -p /workspace/notebooks /workspace/prompts /workspace/experiments

# Create welcome notebook
RUN cat > /workspace/notebooks/Welcome.ipynb << 'EOF'
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Welcome to AI Development Environment\n",
    "\n",
    "This notebook provides an introduction to the AI development environment for the Open WebUI Installer project.\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "### AI Libraries\n",
    "- **OpenAI**: GPT models and embeddings\n",
    "- **Anthropic**: Claude models\n",
    "- **LangChain**: LLM application framework\n",
    "- **Transformers**: Hugging Face model library\n",
    "- **Sentence Transformers**: Text embeddings\n",
    "\n",
    "### Data Science\n",
    "- **Pandas**: Data manipulation and analysis\n",
    "- **NumPy**: Numerical computing\n",
    "- **Matplotlib/Seaborn**: Data visualization\n",
    "- **Scikit-learn**: Machine learning\n",
    "\n",
    "### Vector Databases\n",
    "- **ChromaDB**: Open-source embedding database\n",
    "- **FAISS**: Facebook AI Similarity Search\n",
    "- **Pinecone**: Managed vector database\n",
    "- **Weaviate**: Open-source vector search engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the environment\n",
    "import sys\n",
    "import pkg_resources\n",
    "\n",
    "print(f\"ðŸ Python Version: {sys.version}\")\n",
    "print(f\"ðŸ“¦ Installed Packages: {len(list(pkg_resources.working_set))}\")\n",
    "\n",
    "# Test key libraries\n",
    "try:\n",
    "    import openai\n",
    "    print(\"âœ… OpenAI library available\")\n",
    "except ImportError:\n",
    "    print(\"âŒ OpenAI library not available\")\n",
    "\n",
    "try:\n",
    "    import anthropic\n",
    "    print(\"âœ… Anthropic library available\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Anthropic library not available\")\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    print(\"âœ… LangChain library available\")\n",
    "except ImportError:\n",
    "    print(\"âŒ LangChain library not available\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    print(\"âœ… Transformers library available\")\n",
    "except ImportError:\n",
    "    print(\"âŒ Transformers library not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "1. **Set up API keys** in your environment variables\n",
    "2. **Create new notebooks** for your experiments\n",
    "3. **Use the prompts** in `/workspace/prompts/` for consistent AI interactions\n",
    "4. **Save your work** regularly\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore the example notebooks\n",
    "- Try the AI assistant CLI: `ai-assistant.py --help`\n",
    "- Create custom prompt templates\n",
    "- Experiment with different AI models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
EOF

# Create sample prompts
RUN cat > /workspace/prompts/code_generation.md << 'EOF'
# Code Generation Prompt

**Description:** Generate Python code for the Open WebUI Installer project
**Created:** 2024-01-01 00:00:00

## Context
You are working on the Open WebUI Installer project, which helps users easily install and manage Open WebUI (a user-friendly AI interface). The project should be:
- macOS focused (Linux and Windows support planned)
- Docker-based for isolation
- User-friendly with clear error messages
- Well-tested and documented

## Instructions
Generate Python code that follows these requirements:
1. Use type hints for all function parameters and return values
2. Include comprehensive docstrings
3. Handle errors gracefully with informative messages
4. Follow PEP 8 style guidelines
5. Include basic unit tests
6. Consider Docker integration

## Expected Output
- Clean, readable Python code
- Proper error handling
- Type annotations
- Docstrings
- Basic test cases

## Examples
```python
def install_openwebui(
    port: int = 3000,
    docker_image: str = "ghcr.io/open-webui/open-webui:main"
) -> bool:
    """Install and start Open WebUI using Docker.

    Args:
        port: Port to run Open WebUI on (default: 3000)
        docker_image: Docker image to use (default: latest main)

    Returns:
        bool: True if installation successful, False otherwise

    Raises:
        DockerError: If Docker is not available or fails
        PermissionError: If insufficient permissions
    """
    # Implementation here
    pass
```

## Notes
- Prioritize user experience and clear error messages
- Consider offline scenarios where possible
- Maintain compatibility with existing Docker installations
- Keep the installer simple and reliable
EOF

RUN cat > /workspace/prompts/debugging.md << 'EOF'
# Debugging Prompt

**Description:** Debug issues in the Open WebUI Installer project
**Created:** 2024-01-01 00:00:00

## Context
- Docker-related issues (common)
- macOS compatibility problems
- Network and port conflicts
- Permission and access issues
- Installation and dependency problems

## Instructions
When debugging:
1. Analyze the error message thoroughly
2. Consider the user's environment (OS, Docker version, permissions)
3. Provide step-by-step troubleshooting
4. Suggest multiple solutions when possible
5. Include prevention measures
6. Consider logging and diagnostics

## Expected Output
- Root cause analysis
- Step-by-step troubleshooting guide
- Multiple solution options
- Prevention recommendations
- Improved error handling code

## Examples
For Docker connection errors:
1. Check if Docker is running
2. Verify user permissions for Docker
3. Test Docker with simple command
4. Check for port conflicts
5. Verify Docker daemon configuration

## Notes
- Docker issues are the most common problems
- Port conflicts happen frequently (3000, 8080)
- Permission issues vary by operating system
- Network connectivity can affect Docker pulls
- Always provide user-friendly error messages
EOF

# Set up JupyterLab configuration
RUN jupyter lab --generate-config

RUN cat >> /root/.jupyter/jupyter_lab_config.py << 'EOF'
# AI Development Environment Configuration
c.ServerApp.ip = '0.0.0.0'
c.ServerApp.port = 8889
c.ServerApp.open_browser = False
c.ServerApp.allow_root = True
c.ServerApp.token = ''
c.ServerApp.password = ''
c.ServerApp.allow_origin = '*'
c.ServerApp.disable_check_xsrf = True
c.ServerApp.notebook_dir = '/workspace'
EOF

# Create startup script
RUN cat > /usr/local/bin/entrypoint.sh << 'EOF'
#!/bin/bash
echo "ðŸ§  AI Development Environment Starting..."
echo "ðŸš€ JupyterLab: http://localhost:8889"
echo "ðŸ“ Workspace: /workspace"
echo "ðŸ”§ CLI Assistant: ai-assistant.py --help"
echo ""

# Set up Git if not configured
if [ ! -f /root/.gitconfig ]; then
    git config --global user.name "AI Developer"
    git config --global user.email "ai@localhost"
    git config --global init.defaultBranch main
fi

# Start JupyterLab
exec /usr/local/bin/start-jupyter.sh
EOF

RUN chmod +x /usr/local/bin/entrypoint.sh

# Expose JupyterLab port
EXPOSE 8889

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8889/lab || exit 1

# Set working directory
WORKDIR /workspace

# Default command
CMD ["/usr/local/bin/entrypoint.sh"]
